{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c9edbf",
   "metadata": {},
   "source": [
    "# Model Introduction\n",
    "\n",
    "The model is downloaded from Huggingface for different stereotypes detection. When a single sentence is passed into the model, it can identify nine classes inclusing gender stereotypes. Therefore the article utilizes the model to calculate the gender stereotype scores within each sentence then obtain the average score of an entire article. See the details: https://huggingface.co/wu981526092/Sentence-Level-Stereotype-Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "043534dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Setting\\Miniconda\\envs\\feyy3.11wogpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ee9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "f:\\Python\\Setting\\Miniconda\\envs\\feyy3.11wogpu\\Lib\\site-packages\\torch\\cuda\\__init__.py:287: UserWarning: \n",
      "NVIDIA GeForce RTX 5060 Laptop GPU with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_75 sm_80 sm_86 sm_89 sm_90 compute_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5060 Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "detector = pipeline (\n",
    "\t\"text-classification\",\n",
    "\tmodel=\"../models/wu981526092\",\n",
    "\ttokenizer=\"../models/wu981526092\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352923f",
   "metadata": {},
   "source": [
    "# Process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9e4f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"../data/splited/m_ir_ms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e349cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = spacy.load(\"en_core_web_sm\")  # run python -m spacy download en_core_web_sm in cmd\n",
    "def sent_tokenize(text):\n",
    "    doc = tokenizer(text) # the result is doc!\n",
    "    return [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc688dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "avg_scores = []\n",
    "for idx, row in news.iterrows():\n",
    "    sentences = sent_tokenize(str(row['content']))\n",
    "    scores = []\n",
    "    for sent in sentences:\n",
    "        result = detector(sent)\n",
    "        # only consider gender stereotypes\n",
    "        gender_scores = [r['score'] for r in result if r['label'] == 'stereotype_gender']\n",
    "        if gender_scores:\n",
    "            scores.extend(gender_scores)\n",
    "    \n",
    "    # if the news does not contain gender stereotypes, the score will be marked as 0\n",
    "    avg_score = sum(scores) / len(sentences) if scores else 0\n",
    "    avg_scores.append(avg_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23037ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['stereotype_score'] = avg_scores\n",
    "news_sorted = news.sort_values(by='stereotype_score', ascending=False)\n",
    "news_sorted.to_csv(\"../data/stereotype_calculated/m_ir_ms_with_stereotype_score.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feyy3.11wogpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
