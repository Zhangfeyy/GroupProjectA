{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7c67a99",
   "metadata": {},
   "source": [
    "# H1\n",
    "\n",
    "H1: Mainstream media in both Ireland and Nepal are more likely to emphasise female stereotypes, such as personal attributes (e.g., appearance, family roles), of female politicians rather than their political achievements.\n",
    "\n",
    "The hypothesis treats stereotypes as the dependent variable (DV), with nation and media type as independent variables (IVs). Both IVs are binary (Nepal/Ireland and alternative/mainstream), while the DV is a numerical value calculated by the model. However, the DV is highly skewed, with approximately 60% of cases being 0 (no stereotypes). Therefore, a two-part modeling approach was adopted:\n",
    "\n",
    "1. Do nation and media type influence the presence of stereotypes?\n",
    "The DV was first converted into a binary variable: 0 (no stereotypes) and 1 (stereotypes present). Logit regression was then conducted to examine the effects of nation and media type on the existence of stereotypes.\n",
    "\n",
    "2. Do nation and media type influence the degree of stereotypes?\n",
    "Next, articles without stereotypes were excluded, and linear regression was performed on the remaining data to assess how nation and media type affect the degree of stereotypes.\n",
    "\n",
    "To be noticed that, the stereotype was calculated in articles only mentioning female or male, to maximum remove the noise of co-existence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "399e4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7a43bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the datset and add addtributes\n",
    "df1 = pd.read_csv(\"../data/stereotype_calculated/f_ir_al_with_stereotype_score.csv\")\n",
    "df1[\"nation\"] = \"ir\"\n",
    "df1[\"type\"] = \"al\"\n",
    "\n",
    "df2 = pd.read_csv(\"../data/stereotype_calculated/f_ir_ms_with_stereotype_score.csv\")\n",
    "df2[\"nation\"] = \"ir\"\n",
    "df2[\"type\"] = \"ms\"\n",
    "\n",
    "df3 = pd.read_csv(\"../data/stereotype_calculated/f_np_al_with_stereotype_score.csv\")\n",
    "df3[\"nation\"] = \"np\"\n",
    "df3[\"type\"] = \"al\"\n",
    "\n",
    "df4 = pd.read_csv(\"../data/stereotype_calculated/f_np_ms_with_stereotype_score.csv\")\n",
    "df4[\"nation\"] = \"np\"\n",
    "df4[\"type\"] = \"ms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "481bf36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "sum_dataset = pd.DataFrame()\n",
    "sum_dataset = pd.concat([sum_dataset,df1,df2,df3,df4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f38abd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181 entries, 0 to 180\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   date              181 non-null    object \n",
      " 1   content           181 non-null    object \n",
      " 2   female            181 non-null    int64  \n",
      " 3   male              181 non-null    int64  \n",
      " 4   stereotype_score  181 non-null    float64\n",
      " 5   nation            181 non-null    object \n",
      " 6   type              181 non-null    object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 10.0+ KB\n",
      "None\n",
      "        date                                            content  female  male  \\\n",
      "0  2024/9/13  \"They saved his life\" - Mary Lou McDonald’s hu...       1     0   \n",
      "1  2024/7/18  Dublin man arrested after online threats again...       1     0   \n",
      "2  2024/7/19  \"I didn’t mean it to go so viral\" - Dublin man...       1     0   \n",
      "3  2024/7/17  Irish man threatens to kill Mary Lou McDonald ...       1     0   \n",
      "4  2024/10/4  Galway farmer convicted after flinging cow dun...       1     0   \n",
      "\n",
      "   stereotype_score nation type  \n",
      "0          0.179862     ir   al  \n",
      "1          0.094298     ir   al  \n",
      "2          0.091431     ir   al  \n",
      "3          0.060591     ir   al  \n",
      "4          0.058141     ir   al  \n"
     ]
    }
   ],
   "source": [
    "# Inspect the new dataset\n",
    "print(sum_dataset.info())\n",
    "print(sum_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c5728f",
   "metadata": {},
   "source": [
    "## Part 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbb7418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = sum_dataset\n",
    "dataset1[\"stereotype_score\"] = (dataset1[\"stereotype_score\"] > 0 ).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a60b70",
   "metadata": {},
   "source": [
    "Before conducting regression, the study inspected VIF to ensure the weak correlation between IVs. Both VIFs for nation and type are around 1 and less than 10, indicating the ideal condition for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad306536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "date                0\n",
      "content             0\n",
      "female              0\n",
      "male                0\n",
      "stereotype_score    0\n",
      "nation              0\n",
      "type                0\n",
      "dtype: int64\n",
      "\n",
      "DV:\n",
      "stereotype_score\n",
      "0    111\n",
      "1     70\n",
      "Name: count, dtype: int64\n",
      "\n",
      "VIF\n",
      "    variable       VIF\n",
      "0  nation_np  1.006250\n",
      "1    type_ms  1.006250\n",
      "2  intercept  6.106105\n"
     ]
    }
   ],
   "source": [
    "# Prepare for the Regression\n",
    "\n",
    "# 1. Inspect Nulls\n",
    "print('Missing values:')\n",
    "print(dataset1.isnull().sum())\n",
    "\n",
    "# 2. Inspect DV distribution\n",
    "print('\\nDV:')\n",
    "print(dataset1['stereotype_score'].value_counts())\n",
    "\n",
    "# 3. Inspect VIF\n",
    "# since IVs are categorical, they must first be converted into dummy variables then into floats\n",
    "X = pd.get_dummies(dataset1[['nation','type']], drop_first=True)\n",
    "X = X.astype(float)\n",
    "\n",
    "X['intercept'] = 1\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['variable'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(\"\\nVIF\")\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e887bd4",
   "metadata": {},
   "source": [
    "However, the distribution of IVs are skewed as well, resulting in the fail on convenge of the regression model including the interaction effect even with more iterations. Hence, the model was further simplified into the main effect model without the interection term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "371082b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stereotype_score\n",
      "0    111\n",
      "1     70\n",
      "Name: count, dtype: int64\n",
      "nation\n",
      "ir    151\n",
      "np     30\n",
      "Name: count, dtype: int64\n",
      "type\n",
      "ms    151\n",
      "al     30\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset1['stereotype_score'].value_counts())\n",
    "print(dataset1['nation'].value_counts())\n",
    "print(dataset1['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7a83648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.597892\n",
      "         Iterations: 500\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       stereotype_score   No. Observations:                  181\n",
      "Model:                          Logit   Df Residuals:                      177\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 17 Jan 2026   Pseudo R-squ.:                  0.1040\n",
      "Time:                        21:09:31   Log-Likelihood:                -108.22\n",
      "converged:                      False   LL-Null:                       -120.78\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.462e-05\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -0.3747      0.392     -0.957      0.339      -1.142       0.393\n",
      "nation[T.np]              -28.9761   1.36e+06  -2.12e-05      1.000   -2.67e+06    2.67e+06\n",
      "type[T.ms]                  0.2455      0.431      0.570      0.569      -0.599       1.090\n",
      "nation[T.np]:type[T.ms]    25.8473   1.36e+06   1.89e-05      1.000   -2.67e+06    2.67e+06\n",
      "===========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Setting\\Miniconda\\envs\\feyy311\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "# Type conversion\n",
    "dataset1['nation'] = dataset1['nation'].astype('category')\n",
    "dataset1['type'] = dataset1['type'].astype('category')\n",
    "\n",
    "# Construct the model\n",
    "model1 = smf.logit('stereotype_score ~ nation * type', data=dataset1).fit(maxiter=500)\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "629a6204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.598359\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       stereotype_score   No. Observations:                  181\n",
      "Model:                          Logit   Df Residuals:                      178\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 17 Jan 2026   Pseudo R-squ.:                  0.1033\n",
      "Time:                        21:05:45   Log-Likelihood:                -108.30\n",
      "converged:                       True   LL-Null:                       -120.78\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.831e-06\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       -0.3869      0.390     -0.992      0.321      -1.151       0.377\n",
      "nation[T.np]    -3.2173      1.031     -3.120      0.002      -5.238      -1.197\n",
      "type[T.ms]       0.2603      0.429      0.607      0.544      -0.580       1.100\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Type conversion\n",
    "dataset1['nation'] = dataset1['nation'].astype('category')\n",
    "dataset1['type'] = dataset1['type'].astype('category')\n",
    "\n",
    "# Construct the model\n",
    "model1 = smf.logit('stereotype_score ~ nation + type', data=dataset1).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0d71fb",
   "metadata": {},
   "source": [
    "According to the results, only nation (coef_np = -3.217, std = 1.031, p = 0.002, 95% CI = [-5.238, -1.197]) significantly influences the presence of stereotypes in the female context, while media type (coef_ms = 0.260, std = 0.429, p = 0.544, 95% CI = [-0.580, 1.100]) does not have a statistically significant effect. Furthermore, Nepalese media are more likely to contain stereotyped content compared to Irish media. The model explains approximately 10.3% of the variance in the data, indicating moderate explanatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879a8e6",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d5be4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = sum_dataset\n",
    "dataset2 = dataset2[dataset2[\"stereotype_score\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d138a5f",
   "metadata": {},
   "source": [
    "Before conducting regression, the study inspected VIF to ensure weak correlation between independent variables. Both VIFs for nation and type were around 1 and well below 10, indicating ideal conditions for regression. However, for the independent variable nation, there was only one instance for Nepal, meaning the model could not efficiently verify the effect due to insufficient data for that group.\n",
    "\n",
    "The second part cannot be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c03e910a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "date                0\n",
      "content             0\n",
      "female              0\n",
      "male                0\n",
      "stereotype_score    0\n",
      "nation              0\n",
      "type                0\n",
      "dtype: int64\n",
      "\n",
      "DV:\n",
      "stereotype_score\n",
      "0.179862    1\n",
      "0.094298    1\n",
      "0.091431    1\n",
      "0.060591    1\n",
      "0.058141    1\n",
      "           ..\n",
      "0.011474    1\n",
      "0.010542    1\n",
      "0.010384    1\n",
      "0.008315    1\n",
      "0.015264    1\n",
      "Name: count, Length: 70, dtype: int64\n",
      "\n",
      "VIF\n",
      "    variable       VIF\n",
      "0  nation_np  1.002709\n",
      "1    type_ms  1.002709\n",
      "2  intercept  6.363636\n"
     ]
    }
   ],
   "source": [
    "# Prepare for the Regression\n",
    "\n",
    "# 1. Inspect Nulls\n",
    "print('Missing values:')\n",
    "print(dataset2.isnull().sum())\n",
    "\n",
    "# 2. Inspect DV distribution\n",
    "print('\\nDV:')\n",
    "print(dataset2['stereotype_score'].value_counts())\n",
    "\n",
    "# 3. Inspect VIF\n",
    "# since IVs are categorical, they must first be converted into dummy variables then into floats\n",
    "X = pd.get_dummies(dataset2[['nation','type']], drop_first=True)\n",
    "X = X.astype(float)\n",
    "\n",
    "X['intercept'] = 1\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['variable'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(\"\\nVIF\")\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3dd05f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stereotype_score\n",
      "0.179862    1\n",
      "0.094298    1\n",
      "0.091431    1\n",
      "0.060591    1\n",
      "0.058141    1\n",
      "           ..\n",
      "0.011474    1\n",
      "0.010542    1\n",
      "0.010384    1\n",
      "0.008315    1\n",
      "0.015264    1\n",
      "Name: count, Length: 70, dtype: int64\n",
      "nation\n",
      "ir    69\n",
      "np     1\n",
      "Name: count, dtype: int64\n",
      "type\n",
      "ms    59\n",
      "al    11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset2['stereotype_score'].value_counts())\n",
    "print(dataset2['nation'].value_counts())\n",
    "print(dataset2['type'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feyy311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
